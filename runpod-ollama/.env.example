# Nala AI - Environment Configuration for Ollama Integration

# Existing Variables (keep these)
RUNPOD_API_KEY=your_existing_runpod_key_here
RUNPOD_ENDPOINT=https://api.runpod.ai/v2/m4ri0is2v69hu1/run
OPENAI_API_KEY=your_openai_key_here
CLAUDE_API_KEY=your_claude_key_here

# New Ollama Variables
RUNPOD_OLLAMA_ENDPOINT=https://api.runpod.ai/v2/YOUR_OLLAMA_ENDPOINT_ID/run
RUNPOD_OLLAMA_ENABLED=true

# Alternative: Direct Ollama Endpoint (if running your own)
OLLAMA_ENDPOINT=https://your-ollama-instance.runpod.io
OLLAMA_API_KEY=optional_if_auth_required

# DeepSeek Model Configuration (for RunPod container)
DEEPSEEK_MODEL=deepseek-r1:8b

# Phase Controls
PHASE2_ENABLED=true
PHASE3_ENABLED=true
OPENAI_ENABLED=true

# Performance Tuning
API_TIMEOUT=300000
MAX_PARALLEL_REQUESTS=5